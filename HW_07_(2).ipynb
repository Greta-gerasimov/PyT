{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Greta-gerasimov/PyT/blob/L7_sequences_PyT/HW_07_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pLKUIwjDRFe",
        "outputId": "acab959b-3e80-4863-a1b7-9a27b24cbdbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: stop-words in /usr/local/lib/python3.10/dist-packages (2018.7.23)\n",
            "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.10/dist-packages (0.9.1)\n",
            "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.7.2)\n",
            "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.10/dist-packages (from pymorphy2) (0.6.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install stop-words pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42sadOE_DjUy",
        "outputId": "8201a2bc-6fdc-495b-fae3-813e3d1d8a64"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.2.0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.23.5)\n",
            "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.1.0+cu118)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.9.0)\n",
            "Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (23.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGYq3UpJDRFm",
        "outputId": "15195637-efe2-4434-f17a-63365f413fa0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchmetrics\n",
        "\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('wordnet')\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "# from pymorphy2 import MorphAnalyzer\n",
        "\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "1aWSCHwVDRFt"
      },
      "outputs": [],
      "source": [
        "max_words = 1000\n",
        "max_len = 10\n",
        "num_classes = 1\n",
        "\n",
        "epochs = 15\n",
        "batch_size = 512\n",
        "print_batch_n = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "2Pcx4Y1rDRFu"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/twitter_train.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_Fgs11FdDRFw",
        "outputId": "17f4537c-60d6-4f23-a8e0-1ad3455f095e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  label                                              tweet\n",
              "0   1      0   @user when a father is dysfunctional and is s...\n",
              "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
              "2   3      0                                bihday your majesty\n",
              "3   4      0  #model   i love u take with u all the time in ...\n",
              "4   5      0             factsguide: society now    #motivation"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d4377dea-1fc3-442e-be2f-fe1d625f6a90\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>@user when a father is dysfunctional and is s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>bihday your majesty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>#model   i love u take with u all the time in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>factsguide: society now    #motivation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d4377dea-1fc3-442e-be2f-fe1d625f6a90')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d4377dea-1fc3-442e-be2f-fe1d625f6a90 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d4377dea-1fc3-442e-be2f-fe1d625f6a90');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8d92abad-c6d8-4fc5-9112-c0337ee0a21a\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8d92abad-c6d8-4fc5-9112-c0337ee0a21a')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8d92abad-c6d8-4fc5-9112-c0337ee0a21a button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ],
      "source": [
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdjkYaUgDRFy",
        "outputId": "67c7ac3a-93d2-4da7-aad1-467703ae104e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    29720\n",
              "1     2242\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ],
      "source": [
        "train_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TG9u7y-uDRF0",
        "outputId": "08788dcd-5e86-4d4f-ab45-3429788df9b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((23971, 3), (7991, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 128
        }
      ],
      "source": [
        "X_train, X_valid = train_test_split(train_df, test_size=0.25, random_state=42)\n",
        "X_train.shape, X_valid.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6gvqu_0mDRF1",
        "outputId": "049f60a8-6732-472e-8b33-929ba475f701"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    22288\n",
              "1     1683\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ],
      "source": [
        "X_train.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UoZo60ytDRF3",
        "outputId": "0f749e58-2a45-447a-a1c8-fd4f0e1c1042"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    7432\n",
              "1     559\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ],
      "source": [
        "X_valid.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "ISs3Tb22DRF5"
      },
      "outputs": [],
      "source": [
        "sw = set(get_stop_words(\"en\"))\n",
        "# sw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "id": "9v46D6PjDRF7"
      },
      "outputs": [],
      "source": [
        "puncts = set(punctuation)\n",
        "# puncts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "d78-zROlDRF9",
        "outputId": "7159c959-28e5-4cd2-95bb-91b3abad430f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dog'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "# morpher = MorphAnalyzer() # это для русского\n",
        "morpher = WordNetLemmatizer()\n",
        "morpher.lemmatize('dogs')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "j7SYeLmoDRGX"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in puncts)\n",
        "    txt = txt.lower()\n",
        "#     txt = re.sub(\"не\\s\", \"не\", txt)\n",
        "    txt = [morpher.lemmatize(word) for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "vSmdCge9DRGZ"
      },
      "outputs": [],
      "source": [
        "# train_df.tweet.iloc[:1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "EkyxIQZRDRGa"
      },
      "outputs": [],
      "source": [
        "# train_df.tweet.iloc[:1].apply(preprocess_text).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsEF7VWvDRGb",
        "outputId": "e3019f0f-068b-482a-855e-3afe2a9971a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 23971/23971 [00:02<00:00, 8833.58it/s] \n",
            "100%|██████████| 7991/7991 [00:00<00:00, 18426.37it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "\n",
        "X_train.tweet = X_train.tweet.progress_apply(preprocess_text)\n",
        "X_valid.tweet = X_valid.tweet.progress_apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QN-GCjjvDRGc",
        "outputId": "2fa617a5-5794-48d0-e9e6-fcc88b269ef8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['weekend', 'world', 'really', 'going', 'bonkers']"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ],
      "source": [
        "train_corpus = \" \".join(X_train.tweet)\n",
        "train_corpus = train_corpus.lower()\n",
        "tokens = word_tokenize(train_corpus)\n",
        "tokens[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "D6rOOq70DRGd"
      },
      "outputs": [],
      "source": [
        "# Отфильтруем данные и соберём в корпус N наиболее частых токенов\n",
        "tokens_filtered = [word for word in tokens if word.isalnum()]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZmfNa6XDRGe",
        "outputId": "f26986aa-ee5b-4dda-abd7-61e665f24db6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "999"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ],
      "source": [
        "from nltk.probability import FreqDist\n",
        "\n",
        "dist = FreqDist(tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]  # вычитание 1 для padding\n",
        "len(tokens_filtered_top)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssk0Zm3EDRGf",
        "outputId": "a4cf566e-8143-4388-d48c-443132161ebc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['user', 'love', 'day', 'u', 'happy', 'amp', 'just', 'will', 'time', 'life']"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "source": [
        "tokens_filtered_top[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "scrolled": false,
        "id": "Mgc-I4sDDRGg"
      },
      "outputs": [],
      "source": [
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}\n",
        "# vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "id": "asTnf5sNDRGh"
      },
      "outputs": [],
      "source": [
        "def text_to_sequence(text, maxlen):\n",
        "\n",
        "    result = []\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens_filtered = [word for word in tokens if word.isalnum()] # проверка чтобы токен был либо буквенный либо символьный\n",
        "    for word in tokens_filtered:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "\n",
        "    padding = [0] * (maxlen-len(result))\n",
        "\n",
        "    return result[-maxlen:] + padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV703nZqDRGi",
        "outputId": "08f1c571-b65b-49e9-cf16-be6dd3aa9fc9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((23971, 10), (7991, 10))"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ],
      "source": [
        "x_train = np.asarray([text_to_sequence(text, max_len) for text in X_train.tweet])\n",
        "x_val = np.asarray([text_to_sequence(text, max_len) for text in X_valid.tweet])\n",
        "\n",
        "x_train.shape, x_val.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "B1u4IAOtDRGj",
        "outputId": "3a86e172-4753-4425-d92b-74f5ec1c0134"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 145
        }
      ],
      "source": [
        "train_df.tweet.iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F6EqPNaDRGk",
        "outputId": "d4778664-fcd6-4311-c560-61696c42cf6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([35,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ],
      "source": [
        "x_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {
        "id": "MmJY4DtdDRGl"
      },
      "outputs": [],
      "source": [
        "# class Net(nn.Module):\n",
        "#     def __init__(self, vocab_size=2000, embedding_dim=64, out_channel=64, num_classes=1):\n",
        "#         super().__init__()\n",
        "#         self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "#         self.conv_1 = nn.Conv1d(embedding_dim, out_channel, kernel_size=2)\n",
        "#         self.conv_2 = nn.Conv1d(embedding_dim, out_channel, kernel_size=3)\n",
        "#         self.pool = nn.MaxPool1d(2)\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.linear_1 = nn.Linear(out_channel, out_channel // 2)\n",
        "#         self.linear_2 = nn.Linear(out_channel // 2, num_classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         output = self.embedding(x) # B, L, E\n",
        "#         #                       B  E  L\n",
        "#         output = output.permute(0, 2, 1)\n",
        "#         output = self.conv_1(output)\n",
        "#         output = self.relu(output)\n",
        "#         output = self.pool(output)\n",
        "\n",
        "#         output = self.conv_2(output)\n",
        "#         output = self.relu(output)\n",
        "#         output = self.pool(output)\n",
        "#         output = torch.max(output, axis=2).values\n",
        "#         output = self.linear_1(output)\n",
        "#         output = self.relu(output)\n",
        "#         output = self.linear_2(output)\n",
        "#         output = F.sigmoid(output)\n",
        "#         return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {
        "id": "rA_J2JoODRGm"
      },
      "outputs": [],
      "source": [
        "class GRUFixedLen(nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim=128, hidden_dim=128, drop_prob=0.1, use_last=True):\n",
        "        super().__init__()\n",
        "        self.use_last = use_last\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True, dropout=drop_prob)\n",
        "        self.linear = nn.Linear(hidden_dim, 1)\n",
        "#         self.dropout = nn.Dropout(drop_prob)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embeddings(x)\n",
        "#         x = self.dropout(x)\n",
        "        gru_out, ht = self.gru(x)\n",
        "\n",
        "        if self.use_last:\n",
        "            last_tensor = gru_out[:,-1,:]\n",
        "        else:\n",
        "            # use mean\n",
        "            last_tensor = torch.mean(gru_out[:,:], dim=1)\n",
        "\n",
        "        out = self.linear(last_tensor)\n",
        "        return torch.sigmoid(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "AANrapwaDRGn"
      },
      "outputs": [],
      "source": [
        "class DataWrapper(Dataset):\n",
        "    def __init__(self, data, target, transform=None):\n",
        "        self.data = torch.from_numpy(data).long() # если индексы инты то делать лучше лонг - иначе может сломаться вдруг -\n",
        "        # так как на инт меньше памяти выделяется на каждое значение и может переполниться\n",
        "        self.target = torch.from_numpy(target).long() # какие то ф-и потерь на интах не считается - а только на лонгах\n",
        "        self.transform = transform\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "\n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "8GwvH_NrDRGo"
      },
      "outputs": [],
      "source": [
        "train_dataset = DataWrapper(x_train, X_train.label.values)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "val_dataset = DataWrapper(x_val, X_valid.label.values)\n",
        "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = [5, 10]\n",
        "learning_rates = [1e-2, 1e-3]\n",
        "e_dims = [128, 256]\n",
        "h_dims = [64, 96]\n",
        "ths = [0.3, 0.5]\n",
        "dps = [0.1, 0.2, 0.3]"
      ],
      "metadata": {
        "id": "4TLLTrD_T-S2"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bHRlPpvDRGq",
        "outputId": "86563168-a2fb-486a-9a15-c1daaf12da7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([512, 10])\n",
            "torch.Size([512])\n",
            "tensor(0)\n"
          ]
        }
      ],
      "source": [
        "for x, l in train_loader:\n",
        "    print(x.shape)\n",
        "    print(l.shape)\n",
        "    print(l[0])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0O-jePpDRGp",
        "outputId": "081730a6-a432-400f-d512-a59af22c4ce2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.sampler.RandomSampler at 0x7f37738f6110>"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ],
      "source": [
        "train_loader.sampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {
        "id": "52k_3UJ4DRGt"
      },
      "outputs": [],
      "source": [
        "model = GRUFixedLen(max_words)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4Kvpl_mDRGu",
        "outputId": "e41ab5ec-8810-4ae0-801e-231bfe324edd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRUFixedLen(\n",
            "  (embeddings): Embedding(1000, 128, padding_idx=0)\n",
            "  (gru): GRU(128, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (linear): Linear(in_features=128, out_features=1, bias=True)\n",
            ")\n",
            "Parameters: 326273\n"
          ]
        }
      ],
      "source": [
        "print(model)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epochs in n_epochs:\n",
        "    for lr in learning_rates:\n",
        "        for embedding_dim in e_dims:\n",
        "            for hidden_dim in h_dims:\n",
        "                for th in ths:\n",
        "                    for dp in dps:\n",
        "\n",
        "                        print(f'Hyper params: epochs - {epochs}, learning_rate - {lr}, '\n",
        "                             f'embedding_dim - {embedding_dim}, hidden_dim - {hidden_dim}, '\n",
        "                             f'threshold_level - {th}, drop_prob - {dp}.')\n",
        "                        model = GRUFixedLen(vocab_size=max_words,\n",
        "                                             embedding_dim=embedding_dim, hidden_dim=hidden_dim,\n",
        "                                             drop_prob=dp, use_last=False)\n",
        "                        optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "                        model.train()\n",
        "                        th = th\n",
        "\n",
        "                        train_loss_history = []\n",
        "                        test_loss_history = []\n",
        "\n",
        "\n",
        "                        for epoch in range(epochs):\n",
        "                            running_items, running_right = 0.0, 0.0\n",
        "                            for i, data in enumerate(train_loader, 0):\n",
        "                                inputs, labels = data[0], data[1]\n",
        "\n",
        "                                # обнуляем градиент\n",
        "                                optimizer.zero_grad()\n",
        "                                outputs = model(inputs)\n",
        "\n",
        "                                loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "                                loss.backward()\n",
        "                                optimizer.step()\n",
        "\n",
        "                                # подсчет ошибки на обучении\n",
        "                                loss = loss.item()\n",
        "                                running_items += len(labels)\n",
        "                                # подсчет метрики на обучении\n",
        "                                pred_labels = torch.squeeze((outputs > th).int())\n",
        "                                running_right += (labels == pred_labels).sum()\n",
        "\n",
        "                            # выводим статистику о процессе обучения\n",
        "                            model.eval()\n",
        "\n",
        "                            print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "                                    f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "                                    f'Loss: {loss:.3f}. ' \\\n",
        "                                    f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "                            running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "                            train_loss_history.append(loss)\n",
        "\n",
        "                                # выводим статистику на тестовых данных\n",
        "                            test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
        "                            for j, data in enumerate(val_loader):\n",
        "                                test_labels = data[1].to(device)\n",
        "                                test_outputs = model(data[0].to(device))\n",
        "\n",
        "                                # подсчет ошибки на тесте\n",
        "                                test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "                                # подсчет метрики на тесте\n",
        "                                test_running_total += len(data[1])\n",
        "                                pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "                                test_running_right += (test_labels == pred_test_labels).sum()\n",
        "\n",
        "                            test_loss_history.append(test_loss.item())\n",
        "                            print(f'Test loss: {test_loss:.3f}.'\n",
        "                                  f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "\n",
        "                            model.train()\n",
        "\n",
        "                        print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "msx64jGOTtku",
        "outputId": "b06798ee-cd1c-4378-9ce1-781d455bd7cf"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.169. Acc: 0.897. Test loss: 0.178.Test acc: 0.944\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.130. Acc: 0.946. Test loss: 0.070.Test acc: 0.935\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.136. Acc: 0.953. Test loss: 0.221.Test acc: 0.940\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.091. Acc: 0.960. Test loss: 0.016.Test acc: 0.935\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.096. Acc: 0.968. Test loss: 0.849.Test acc: 0.938\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.163. Acc: 0.896. Test loss: 1.318.Test acc: 0.940\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.121. Acc: 0.948. Test loss: 0.063.Test acc: 0.936\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.136. Acc: 0.953. Test loss: 0.119.Test acc: 0.943\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.127. Acc: 0.962. Test loss: 0.005.Test acc: 0.936\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.114. Acc: 0.971. Test loss: 0.008.Test acc: 0.937\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.186. Acc: 0.896. Test loss: 0.018.Test acc: 0.933\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.150. Acc: 0.948. Test loss: 0.333.Test acc: 0.939\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.138. Acc: 0.952. Test loss: 0.029.Test acc: 0.944\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.118. Acc: 0.963. Test loss: 0.213.Test acc: 0.939\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.049. Acc: 0.970. Test loss: 0.087.Test acc: 0.936\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.140. Acc: 0.924. Test loss: 0.024.Test acc: 0.944\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.147. Acc: 0.952. Test loss: 0.023.Test acc: 0.947\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.131. Acc: 0.958. Test loss: 0.013.Test acc: 0.948\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.119. Acc: 0.964. Test loss: 0.001.Test acc: 0.948\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.119. Acc: 0.971. Test loss: 0.019.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.145. Acc: 0.921. Test loss: 0.104.Test acc: 0.944\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.144. Acc: 0.950. Test loss: 0.012.Test acc: 0.949\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.205. Acc: 0.958. Test loss: 0.197.Test acc: 0.948\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.134. Acc: 0.964. Test loss: 0.260.Test acc: 0.946\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.097. Acc: 0.971. Test loss: 0.190.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.151. Acc: 0.932. Test loss: 0.046.Test acc: 0.950\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.161. Acc: 0.951. Test loss: 0.034.Test acc: 0.949\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.116. Acc: 0.958. Test loss: 0.022.Test acc: 0.947\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.102. Acc: 0.965. Test loss: 0.009.Test acc: 0.939\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.073. Acc: 0.973. Test loss: 0.044.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.142. Acc: 0.904. Test loss: 0.642.Test acc: 0.937\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.128. Acc: 0.947. Test loss: 0.081.Test acc: 0.945\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.128. Acc: 0.955. Test loss: 0.013.Test acc: 0.945\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.119. Acc: 0.963. Test loss: 0.012.Test acc: 0.937\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.092. Acc: 0.971. Test loss: 0.792.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.202. Acc: 0.902. Test loss: 0.174.Test acc: 0.938\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.191. Acc: 0.947. Test loss: 0.555.Test acc: 0.939\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.146. Acc: 0.952. Test loss: 0.124.Test acc: 0.941\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.109. Acc: 0.962. Test loss: 0.002.Test acc: 0.938\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.048. Acc: 0.971. Test loss: 0.664.Test acc: 0.940\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.275. Acc: 0.902. Test loss: 0.021.Test acc: 0.941\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.154. Acc: 0.948. Test loss: 0.016.Test acc: 0.934\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.103. Acc: 0.954. Test loss: 0.093.Test acc: 0.943\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.126. Acc: 0.960. Test loss: 0.043.Test acc: 0.942\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.083. Acc: 0.966. Test loss: 0.010.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.162. Acc: 0.940. Test loss: 0.111.Test acc: 0.946\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.165. Acc: 0.952. Test loss: 0.007.Test acc: 0.948\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.129. Acc: 0.960. Test loss: 0.213.Test acc: 0.948\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.088. Acc: 0.969. Test loss: 0.304.Test acc: 0.944\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.086. Acc: 0.974. Test loss: 0.014.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.172. Acc: 0.938. Test loss: 0.673.Test acc: 0.946\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.133. Acc: 0.953. Test loss: 0.555.Test acc: 0.946\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.110. Acc: 0.959. Test loss: 0.205.Test acc: 0.946\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.100. Acc: 0.966. Test loss: 0.012.Test acc: 0.944\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.068. Acc: 0.973. Test loss: 0.019.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.138. Acc: 0.940. Test loss: 0.157.Test acc: 0.944\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.208. Acc: 0.952. Test loss: 0.042.Test acc: 0.947\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.119. Acc: 0.958. Test loss: 0.031.Test acc: 0.949\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.105. Acc: 0.965. Test loss: 0.046.Test acc: 0.947\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.103. Acc: 0.971. Test loss: 0.965.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.164. Acc: 0.897. Test loss: 0.055.Test acc: 0.940\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.135. Acc: 0.950. Test loss: 0.016.Test acc: 0.940\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.115. Acc: 0.958. Test loss: 0.540.Test acc: 0.938\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.096. Acc: 0.965. Test loss: 0.291.Test acc: 0.937\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.086. Acc: 0.971. Test loss: 0.003.Test acc: 0.937\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.126. Acc: 0.894. Test loss: 0.759.Test acc: 0.941\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.107. Acc: 0.948. Test loss: 0.008.Test acc: 0.942\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.097. Acc: 0.956. Test loss: 0.003.Test acc: 0.943\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.104. Acc: 0.966. Test loss: 0.015.Test acc: 0.942\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.069. Acc: 0.973. Test loss: 0.004.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.141. Acc: 0.897. Test loss: 0.041.Test acc: 0.943\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.134. Acc: 0.949. Test loss: 0.011.Test acc: 0.941\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.128. Acc: 0.958. Test loss: 0.069.Test acc: 0.943\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.065. Acc: 0.964. Test loss: 0.053.Test acc: 0.943\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.061. Acc: 0.971. Test loss: 0.140.Test acc: 0.936\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.234. Acc: 0.940. Test loss: 0.408.Test acc: 0.945\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.130. Acc: 0.953. Test loss: 0.037.Test acc: 0.949\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.087. Acc: 0.962. Test loss: 0.872.Test acc: 0.948\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.107. Acc: 0.968. Test loss: 0.018.Test acc: 0.948\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.064. Acc: 0.974. Test loss: 0.121.Test acc: 0.938\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.159. Acc: 0.921. Test loss: 0.025.Test acc: 0.944\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.104. Acc: 0.953. Test loss: 0.648.Test acc: 0.948\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.072. Acc: 0.962. Test loss: 0.428.Test acc: 0.947\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.062. Acc: 0.968. Test loss: 0.350.Test acc: 0.950\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.117. Acc: 0.972. Test loss: 0.821.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.161. Acc: 0.935. Test loss: 0.028.Test acc: 0.946\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.098. Acc: 0.955. Test loss: 0.010.Test acc: 0.948\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.098. Acc: 0.961. Test loss: 0.601.Test acc: 0.946\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.076. Acc: 0.969. Test loss: 0.395.Test acc: 0.948\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.088. Acc: 0.976. Test loss: 0.001.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.166. Acc: 0.904. Test loss: 0.031.Test acc: 0.947\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.146. Acc: 0.950. Test loss: 0.231.Test acc: 0.947\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.123. Acc: 0.960. Test loss: 0.007.Test acc: 0.942\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.095. Acc: 0.966. Test loss: 0.386.Test acc: 0.934\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.049. Acc: 0.975. Test loss: 0.003.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.174. Acc: 0.904. Test loss: 0.020.Test acc: 0.940\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.132. Acc: 0.951. Test loss: 0.495.Test acc: 0.943\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.125. Acc: 0.960. Test loss: 0.022.Test acc: 0.934\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.101. Acc: 0.968. Test loss: 0.246.Test acc: 0.943\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.058. Acc: 0.974. Test loss: 0.121.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.180. Acc: 0.908. Test loss: 0.027.Test acc: 0.945\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.187. Acc: 0.951. Test loss: 0.203.Test acc: 0.938\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.115. Acc: 0.957. Test loss: 0.084.Test acc: 0.947\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.077. Acc: 0.967. Test loss: 0.031.Test acc: 0.936\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.063. Acc: 0.975. Test loss: 0.005.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.161. Acc: 0.927. Test loss: 0.446.Test acc: 0.948\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.153. Acc: 0.954. Test loss: 0.078.Test acc: 0.947\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.104. Acc: 0.963. Test loss: 0.690.Test acc: 0.945\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.097. Acc: 0.970. Test loss: 0.022.Test acc: 0.945\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.073. Acc: 0.977. Test loss: 0.012.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.224. Acc: 0.942. Test loss: 0.584.Test acc: 0.948\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.139. Acc: 0.955. Test loss: 0.017.Test acc: 0.948\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.129. Acc: 0.964. Test loss: 0.002.Test acc: 0.948\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.073. Acc: 0.971. Test loss: 1.406.Test acc: 0.947\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.086. Acc: 0.977. Test loss: 0.015.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.01, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.115. Acc: 0.936. Test loss: 0.008.Test acc: 0.948\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.154. Acc: 0.954. Test loss: 0.027.Test acc: 0.949\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.107. Acc: 0.962. Test loss: 0.060.Test acc: 0.946\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.064. Acc: 0.969. Test loss: 0.551.Test acc: 0.944\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.098. Acc: 0.977. Test loss: 0.091.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.208. Acc: 0.674. Test loss: 0.867.Test acc: 0.929\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.156. Acc: 0.939. Test loss: 0.834.Test acc: 0.936\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.139. Acc: 0.944. Test loss: 0.021.Test acc: 0.942\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.126. Acc: 0.947. Test loss: 0.012.Test acc: 0.940\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.136. Acc: 0.950. Test loss: 0.083.Test acc: 0.943\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.208. Acc: 0.657. Test loss: 0.216.Test acc: 0.937\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.175. Acc: 0.938. Test loss: 0.055.Test acc: 0.942\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.177. Acc: 0.945. Test loss: 0.027.Test acc: 0.941\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.189. Acc: 0.948. Test loss: 0.514.Test acc: 0.937\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.150. Acc: 0.949. Test loss: 0.043.Test acc: 0.944\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.244. Acc: 0.667. Test loss: 0.062.Test acc: 0.934\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.186. Acc: 0.938. Test loss: 0.226.Test acc: 0.941\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.167. Acc: 0.945. Test loss: 0.358.Test acc: 0.943\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.123. Acc: 0.948. Test loss: 0.046.Test acc: 0.938\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.178. Acc: 0.950. Test loss: 0.130.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.242. Acc: 0.881. Test loss: 0.378.Test acc: 0.933\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.159. Acc: 0.940. Test loss: 0.032.Test acc: 0.942\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.166. Acc: 0.950. Test loss: 0.033.Test acc: 0.946\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.095. Acc: 0.953. Test loss: 0.097.Test acc: 0.948\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.169. Acc: 0.955. Test loss: 0.024.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.177. Acc: 0.895. Test loss: 0.071.Test acc: 0.935\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.218. Acc: 0.941. Test loss: 0.030.Test acc: 0.944\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.202. Acc: 0.949. Test loss: 0.043.Test acc: 0.946\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.155. Acc: 0.952. Test loss: 0.042.Test acc: 0.948\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.118. Acc: 0.954. Test loss: 0.524.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.291. Acc: 0.901. Test loss: 0.500.Test acc: 0.932\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.197. Acc: 0.937. Test loss: 0.052.Test acc: 0.943\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.152. Acc: 0.948. Test loss: 0.083.Test acc: 0.947\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.146. Acc: 0.951. Test loss: 0.089.Test acc: 0.947\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.126. Acc: 0.955. Test loss: 0.032.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.191. Acc: 0.728. Test loss: 0.302.Test acc: 0.934\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.138. Acc: 0.940. Test loss: 0.148.Test acc: 0.939\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.130. Acc: 0.942. Test loss: 0.023.Test acc: 0.943\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.128. Acc: 0.948. Test loss: 0.059.Test acc: 0.943\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.115. Acc: 0.950. Test loss: 0.028.Test acc: 0.940\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.213. Acc: 0.741. Test loss: 0.111.Test acc: 0.929\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.158. Acc: 0.937. Test loss: 0.041.Test acc: 0.937\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.129. Acc: 0.944. Test loss: 0.195.Test acc: 0.943\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.122. Acc: 0.948. Test loss: 0.023.Test acc: 0.946\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.168. Acc: 0.950. Test loss: 0.588.Test acc: 0.942\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.162. Acc: 0.738. Test loss: 0.207.Test acc: 0.940\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.157. Acc: 0.939. Test loss: 0.044.Test acc: 0.938\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.114. Acc: 0.945. Test loss: 0.019.Test acc: 0.938\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.128. Acc: 0.948. Test loss: 0.031.Test acc: 0.934\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.103. Acc: 0.950. Test loss: 0.037.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.199. Acc: 0.914. Test loss: 0.122.Test acc: 0.935\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.186. Acc: 0.942. Test loss: 0.527.Test acc: 0.945\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.145. Acc: 0.950. Test loss: 0.038.Test acc: 0.945\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.124. Acc: 0.953. Test loss: 0.158.Test acc: 0.948\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.115. Acc: 0.955. Test loss: 0.396.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.173. Acc: 0.932. Test loss: 0.060.Test acc: 0.937\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.186. Acc: 0.943. Test loss: 0.025.Test acc: 0.943\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.127. Acc: 0.949. Test loss: 0.018.Test acc: 0.948\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.179. Acc: 0.953. Test loss: 0.554.Test acc: 0.948\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.122. Acc: 0.954. Test loss: 0.277.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 128, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.188. Acc: 0.924. Test loss: 0.050.Test acc: 0.939\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.167. Acc: 0.944. Test loss: 0.831.Test acc: 0.945\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.152. Acc: 0.951. Test loss: 0.021.Test acc: 0.945\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.105. Acc: 0.953. Test loss: 0.089.Test acc: 0.945\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.152. Acc: 0.955. Test loss: 0.037.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.252. Acc: 0.690. Test loss: 0.519.Test acc: 0.937\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.158. Acc: 0.941. Test loss: 0.049.Test acc: 0.944\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.182. Acc: 0.949. Test loss: 0.586.Test acc: 0.940\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.141. Acc: 0.950. Test loss: 0.098.Test acc: 0.944\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.103. Acc: 0.955. Test loss: 0.013.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.198. Acc: 0.704. Test loss: 0.067.Test acc: 0.939\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.140. Acc: 0.942. Test loss: 0.028.Test acc: 0.935\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.154. Acc: 0.948. Test loss: 1.197.Test acc: 0.943\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.139. Acc: 0.951. Test loss: 0.029.Test acc: 0.929\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.140. Acc: 0.955. Test loss: 0.053.Test acc: 0.923\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.203. Acc: 0.694. Test loss: 0.051.Test acc: 0.937\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.181. Acc: 0.943. Test loss: 0.135.Test acc: 0.937\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.158. Acc: 0.947. Test loss: 0.095.Test acc: 0.941\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.141. Acc: 0.952. Test loss: 0.113.Test acc: 0.943\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.162. Acc: 0.954. Test loss: 0.357.Test acc: 0.939\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.297. Acc: 0.881. Test loss: 0.369.Test acc: 0.938\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.158. Acc: 0.945. Test loss: 0.060.Test acc: 0.947\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.106. Acc: 0.952. Test loss: 0.040.Test acc: 0.949\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.183. Acc: 0.956. Test loss: 0.034.Test acc: 0.949\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.114. Acc: 0.959. Test loss: 0.072.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.269. Acc: 0.894. Test loss: 0.058.Test acc: 0.936\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.205. Acc: 0.942. Test loss: 0.104.Test acc: 0.945\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.170. Acc: 0.950. Test loss: 0.066.Test acc: 0.948\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.111. Acc: 0.954. Test loss: 0.167.Test acc: 0.948\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.172. Acc: 0.958. Test loss: 0.283.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.203. Acc: 0.926. Test loss: 0.236.Test acc: 0.938\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.149. Acc: 0.945. Test loss: 0.021.Test acc: 0.947\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.121. Acc: 0.953. Test loss: 0.066.Test acc: 0.950\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.136. Acc: 0.956. Test loss: 0.159.Test acc: 0.947\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.073. Acc: 0.959. Test loss: 0.107.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.161. Acc: 0.757. Test loss: 0.080.Test acc: 0.939\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.203. Acc: 0.943. Test loss: 0.338.Test acc: 0.941\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.147. Acc: 0.948. Test loss: 0.053.Test acc: 0.941\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.096. Acc: 0.953. Test loss: 0.054.Test acc: 0.942\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.117. Acc: 0.954. Test loss: 0.096.Test acc: 0.932\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.184. Acc: 0.765. Test loss: 0.388.Test acc: 0.940\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.108. Acc: 0.943. Test loss: 0.376.Test acc: 0.943\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.136. Acc: 0.948. Test loss: 0.068.Test acc: 0.943\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.139. Acc: 0.952. Test loss: 0.012.Test acc: 0.943\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.106. Acc: 0.954. Test loss: 0.021.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.176. Acc: 0.776. Test loss: 0.370.Test acc: 0.938\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.177. Acc: 0.943. Test loss: 0.389.Test acc: 0.941\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.126. Acc: 0.949. Test loss: 0.213.Test acc: 0.936\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.088. Acc: 0.950. Test loss: 0.011.Test acc: 0.944\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.130. Acc: 0.955. Test loss: 0.030.Test acc: 0.941\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.170. Acc: 0.931. Test loss: 0.416.Test acc: 0.942\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.146. Acc: 0.948. Test loss: 0.021.Test acc: 0.947\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.128. Acc: 0.953. Test loss: 0.174.Test acc: 0.949\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.163. Acc: 0.957. Test loss: 0.379.Test acc: 0.948\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.124. Acc: 0.960. Test loss: 0.022.Test acc: 0.947\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.167. Acc: 0.907. Test loss: 0.069.Test acc: 0.941\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.133. Acc: 0.947. Test loss: 0.048.Test acc: 0.946\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.153. Acc: 0.952. Test loss: 0.227.Test acc: 0.948\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.129. Acc: 0.956. Test loss: 0.415.Test acc: 0.950\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.167. Acc: 0.959. Test loss: 0.046.Test acc: 0.949\n",
            "Training is finished!\n",
            "Hyper params: epochs - 5, learning_rate - 0.001, embedding_dim - 256, hidden_dim - 96, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/5]. Step [47/47]. Loss: 0.193. Acc: 0.930. Test loss: 0.643.Test acc: 0.941\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.181. Acc: 0.947. Test loss: 0.058.Test acc: 0.946\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.139. Acc: 0.953. Test loss: 0.040.Test acc: 0.949\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.114. Acc: 0.955. Test loss: 0.023.Test acc: 0.948\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.151. Acc: 0.960. Test loss: 0.101.Test acc: 0.948\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [47/47]. Loss: 0.247. Acc: 0.894. Test loss: 0.056.Test acc: 0.937\n",
            "Epoch [2/10]. Step [47/47]. Loss: 0.145. Acc: 0.948. Test loss: 0.468.Test acc: 0.947\n",
            "Epoch [3/10]. Step [47/47]. Loss: 0.092. Acc: 0.956. Test loss: 0.197.Test acc: 0.945\n",
            "Epoch [4/10]. Step [47/47]. Loss: 0.087. Acc: 0.961. Test loss: 1.201.Test acc: 0.933\n",
            "Epoch [5/10]. Step [47/47]. Loss: 0.051. Acc: 0.971. Test loss: 0.001.Test acc: 0.939\n",
            "Epoch [6/10]. Step [47/47]. Loss: 0.055. Acc: 0.977. Test loss: 0.008.Test acc: 0.939\n",
            "Epoch [7/10]. Step [47/47]. Loss: 0.057. Acc: 0.982. Test loss: 0.284.Test acc: 0.937\n",
            "Epoch [8/10]. Step [47/47]. Loss: 0.047. Acc: 0.983. Test loss: 0.013.Test acc: 0.943\n",
            "Epoch [9/10]. Step [47/47]. Loss: 0.054. Acc: 0.985. Test loss: 0.000.Test acc: 0.942\n",
            "Epoch [10/10]. Step [47/47]. Loss: 0.036. Acc: 0.987. Test loss: 0.811.Test acc: 0.936\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [47/47]. Loss: 0.144. Acc: 0.892. Test loss: 0.818.Test acc: 0.943\n",
            "Epoch [2/10]. Step [47/47]. Loss: 0.112. Acc: 0.947. Test loss: 0.020.Test acc: 0.943\n",
            "Epoch [3/10]. Step [47/47]. Loss: 0.121. Acc: 0.953. Test loss: 0.023.Test acc: 0.936\n",
            "Epoch [4/10]. Step [47/47]. Loss: 0.091. Acc: 0.961. Test loss: 0.002.Test acc: 0.934\n",
            "Epoch [5/10]. Step [47/47]. Loss: 0.076. Acc: 0.968. Test loss: 0.011.Test acc: 0.938\n",
            "Epoch [6/10]. Step [47/47]. Loss: 0.086. Acc: 0.975. Test loss: 0.002.Test acc: 0.938\n",
            "Epoch [7/10]. Step [47/47]. Loss: 0.061. Acc: 0.978. Test loss: 0.014.Test acc: 0.943\n",
            "Epoch [8/10]. Step [47/47]. Loss: 0.072. Acc: 0.982. Test loss: 0.616.Test acc: 0.933\n",
            "Epoch [9/10]. Step [47/47]. Loss: 0.054. Acc: 0.984. Test loss: 0.024.Test acc: 0.920\n",
            "Epoch [10/10]. Step [47/47]. Loss: 0.045. Acc: 0.986. Test loss: 0.051.Test acc: 0.940\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.3, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [47/47]. Loss: 0.163. Acc: 0.900. Test loss: 0.569.Test acc: 0.945\n",
            "Epoch [2/10]. Step [47/47]. Loss: 0.121. Acc: 0.947. Test loss: 0.083.Test acc: 0.944\n",
            "Epoch [3/10]. Step [47/47]. Loss: 0.125. Acc: 0.954. Test loss: 0.026.Test acc: 0.945\n",
            "Epoch [4/10]. Step [47/47]. Loss: 0.133. Acc: 0.960. Test loss: 0.039.Test acc: 0.942\n",
            "Epoch [5/10]. Step [47/47]. Loss: 0.076. Acc: 0.970. Test loss: 1.061.Test acc: 0.938\n",
            "Epoch [6/10]. Step [47/47]. Loss: 0.088. Acc: 0.977. Test loss: 0.052.Test acc: 0.937\n",
            "Epoch [7/10]. Step [47/47]. Loss: 0.054. Acc: 0.981. Test loss: 0.002.Test acc: 0.938\n",
            "Epoch [8/10]. Step [47/47]. Loss: 0.036. Acc: 0.983. Test loss: 0.001.Test acc: 0.940\n",
            "Epoch [9/10]. Step [47/47]. Loss: 0.041. Acc: 0.985. Test loss: 0.172.Test acc: 0.938\n",
            "Epoch [10/10]. Step [47/47]. Loss: 0.038. Acc: 0.987. Test loss: 0.030.Test acc: 0.937\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.1.\n",
            "Epoch [1/10]. Step [47/47]. Loss: 0.170. Acc: 0.939. Test loss: 0.031.Test acc: 0.945\n",
            "Epoch [2/10]. Step [47/47]. Loss: 0.124. Acc: 0.952. Test loss: 0.378.Test acc: 0.947\n",
            "Epoch [3/10]. Step [47/47]. Loss: 0.090. Acc: 0.959. Test loss: 0.007.Test acc: 0.947\n",
            "Epoch [4/10]. Step [47/47]. Loss: 0.087. Acc: 0.966. Test loss: 0.040.Test acc: 0.945\n",
            "Epoch [5/10]. Step [47/47]. Loss: 0.099. Acc: 0.972. Test loss: 0.019.Test acc: 0.944\n",
            "Epoch [6/10]. Step [47/47]. Loss: 0.075. Acc: 0.979. Test loss: 0.059.Test acc: 0.944\n",
            "Epoch [7/10]. Step [47/47]. Loss: 0.043. Acc: 0.984. Test loss: 0.009.Test acc: 0.943\n",
            "Epoch [8/10]. Step [47/47]. Loss: 0.053. Acc: 0.985. Test loss: 0.012.Test acc: 0.942\n",
            "Epoch [9/10]. Step [47/47]. Loss: 0.041. Acc: 0.986. Test loss: 0.058.Test acc: 0.942\n",
            "Epoch [10/10]. Step [47/47]. Loss: 0.032. Acc: 0.988. Test loss: 0.017.Test acc: 0.945\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.2.\n",
            "Epoch [1/10]. Step [47/47]. Loss: 0.122. Acc: 0.922. Test loss: 0.023.Test acc: 0.946\n",
            "Epoch [2/10]. Step [47/47]. Loss: 0.160. Acc: 0.952. Test loss: 0.041.Test acc: 0.949\n",
            "Epoch [3/10]. Step [47/47]. Loss: 0.126. Acc: 0.958. Test loss: 0.062.Test acc: 0.949\n",
            "Epoch [4/10]. Step [47/47]. Loss: 0.117. Acc: 0.966. Test loss: 0.008.Test acc: 0.949\n",
            "Epoch [5/10]. Step [47/47]. Loss: 0.097. Acc: 0.974. Test loss: 0.264.Test acc: 0.944\n",
            "Epoch [6/10]. Step [47/47]. Loss: 0.081. Acc: 0.977. Test loss: 0.005.Test acc: 0.944\n",
            "Epoch [7/10]. Step [47/47]. Loss: 0.081. Acc: 0.981. Test loss: 0.008.Test acc: 0.939\n",
            "Epoch [8/10]. Step [47/47]. Loss: 0.044. Acc: 0.986. Test loss: 2.326.Test acc: 0.943\n",
            "Epoch [9/10]. Step [47/47]. Loss: 0.043. Acc: 0.988. Test loss: 0.001.Test acc: 0.944\n",
            "Epoch [10/10]. Step [47/47]. Loss: 0.044. Acc: 0.988. Test loss: 0.000.Test acc: 0.939\n",
            "Training is finished!\n",
            "Hyper params: epochs - 10, learning_rate - 0.01, embedding_dim - 128, hidden_dim - 64, threshold_level - 0.5, drop_prob - 0.3.\n",
            "Epoch [1/10]. Step [47/47]. Loss: 0.159. Acc: 0.938. Test loss: 0.014.Test acc: 0.943\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-159-1205ebef1fdf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m                                 \u001b[0;31m# обнуляем градиент\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m                                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-148-ea44acfa9283>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m#         x = self.dropout(x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mgru_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mht\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_last\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             result = _VF.gru(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0m\u001b[1;32m   1103\u001b[0m                              self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GRUFixedLen(vocab_size=max_words,\n",
        "                 embedding_dim=256, hidden_dim=64,\n",
        "                 drop_prob=0.1, use_last=False)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCELoss()"
      ],
      "metadata": {
        "id": "n9L1DLxCYiIx"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)\n",
        "print(\"Parameters:\", sum([param.nelement() for param in model.parameters()]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD3Z59JMYpDg",
        "outputId": "1bb4106c-1630-483f-9375-ef3d471fa8d3"
      },
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRUFixedLen(\n",
            "  (embeddings): Embedding(1000, 256, padding_idx=0)\n",
            "  (gru): GRU(256, 64, num_layers=2, batch_first=True, dropout=0.1)\n",
            "  (linear): Linear(in_features=64, out_features=1, bias=True)\n",
            ")\n",
            "Parameters: 342849\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.train()\n",
        "th = 0.5\n",
        "epochs = 10\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_items, running_right = 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0], data[1]\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "        running_items += len(labels)\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        running_right += (labels == pred_labels).sum()\n",
        "\n",
        "    # выводим статистику о процессе обучения\n",
        "    model.eval()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "            f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "            f'Loss: {loss:.3f}. ' \\\n",
        "            f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    train_loss_history.append(loss)\n",
        "\n",
        "        # выводим статистику на тестовых данных\n",
        "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
        "    for j, data in enumerate(val_loader):\n",
        "        test_labels = data[1]\n",
        "        test_outputs = model(data[0])\n",
        "\n",
        "        # подсчет ошибки на тесте\n",
        "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "        # подсчет метрики на тесте\n",
        "        test_running_total += len(data[1])\n",
        "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "        test_running_right += (test_labels == pred_test_labels).sum()\n",
        "\n",
        "    test_loss_history.append(test_loss.item())\n",
        "    print(f'Test loss: {test_loss:.3f}.'\n",
        "          f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "\n",
        "    model.train()\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQmfrvVZfbU0",
        "outputId": "9f405bcc-0589-46d9-ec60-a93f6efd0390"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10]. Step [47/47]. Loss: 0.137. Acc: 0.962. Test loss: 0.007.Test acc: 0.947\n",
            "Epoch [2/10]. Step [47/47]. Loss: 0.081. Acc: 0.966. Test loss: 0.272.Test acc: 0.946\n",
            "Epoch [3/10]. Step [47/47]. Loss: 0.064. Acc: 0.969. Test loss: 0.093.Test acc: 0.943\n",
            "Epoch [4/10]. Step [47/47]. Loss: 0.088. Acc: 0.974. Test loss: 0.013.Test acc: 0.943\n",
            "Epoch [5/10]. Step [47/47]. Loss: 0.066. Acc: 0.980. Test loss: 0.025.Test acc: 0.942\n",
            "Epoch [6/10]. Step [47/47]. Loss: 0.076. Acc: 0.981. Test loss: 0.017.Test acc: 0.945\n",
            "Epoch [7/10]. Step [47/47]. Loss: 0.061. Acc: 0.986. Test loss: 0.002.Test acc: 0.944\n",
            "Epoch [8/10]. Step [47/47]. Loss: 0.042. Acc: 0.988. Test loss: 0.000.Test acc: 0.946\n",
            "Epoch [9/10]. Step [47/47]. Loss: 0.048. Acc: 0.990. Test loss: 0.014.Test acc: 0.942\n",
            "Epoch [10/10]. Step [47/47]. Loss: 0.029. Acc: 0.991. Test loss: 0.020.Test acc: 0.942\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.train()\n",
        "th = 0.5\n",
        "epochs = 5\n",
        "\n",
        "train_loss_history = []\n",
        "test_loss_history = []\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    running_items, running_right = 0.0, 0.0\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data[0], data[1]\n",
        "\n",
        "        # обнуляем градиент\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels.float().view(-1, 1))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # подсчет ошибки на обучении\n",
        "        loss = loss.item()\n",
        "        running_items += len(labels)\n",
        "        # подсчет метрики на обучении\n",
        "        pred_labels = torch.squeeze((outputs > th).int())\n",
        "        running_right += (labels == pred_labels).sum()\n",
        "\n",
        "    # выводим статистику о процессе обучения\n",
        "    model.eval()\n",
        "\n",
        "    print(f'Epoch [{epoch + 1}/{epochs}]. ' \\\n",
        "            f'Step [{i + 1}/{len(train_loader)}]. ' \\\n",
        "            f'Loss: {loss:.3f}. ' \\\n",
        "            f'Acc: {running_right / running_items:.3f}', end='. ')\n",
        "    running_loss, running_items, running_right = 0.0, 0.0, 0.0\n",
        "    train_loss_history.append(loss)\n",
        "\n",
        "        # выводим статистику на тестовых данных\n",
        "    test_running_right, test_running_total, test_loss = 0.0, 0.0, 0.0\n",
        "    for j, data in enumerate(val_loader):\n",
        "        test_labels = data[1]\n",
        "        test_outputs = model(data[0])\n",
        "\n",
        "        # подсчет ошибки на тесте\n",
        "        test_loss = criterion(test_outputs, test_labels.float().view(-1, 1))\n",
        "        # подсчет метрики на тесте\n",
        "        test_running_total += len(data[1])\n",
        "        pred_test_labels = torch.squeeze((test_outputs > th).int())\n",
        "        test_running_right += (test_labels == pred_test_labels).sum()\n",
        "\n",
        "    test_loss_history.append(test_loss.item())\n",
        "    print(f'Test loss: {test_loss:.3f}.'\n",
        "          f'Test acc: {test_running_right / test_running_total:.3f}')\n",
        "\n",
        "    model.train()\n",
        "\n",
        "print('Training is finished!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA7s79PaYTYh",
        "outputId": "f173e061-9b0a-4143-f180-51e684e52773"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]. Step [47/47]. Loss: 0.224. Acc: 0.917. Test loss: 0.595.Test acc: 0.940\n",
            "Epoch [2/5]. Step [47/47]. Loss: 0.113. Acc: 0.947. Test loss: 0.030.Test acc: 0.948\n",
            "Epoch [3/5]. Step [47/47]. Loss: 0.114. Acc: 0.952. Test loss: 0.020.Test acc: 0.949\n",
            "Epoch [4/5]. Step [47/47]. Loss: 0.121. Acc: 0.955. Test loss: 0.176.Test acc: 0.948\n",
            "Epoch [5/5]. Step [47/47]. Loss: 0.116. Acc: 0.959. Test loss: 0.013.Test acc: 0.947\n",
            "Training is finished!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "reOurasLDRG4",
        "outputId": "16f9eecf-dafa-4e1d-d5fc-820128a67eb5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.title('Loss history')\n",
        "plt.grid(True)\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.plot(train_loss_history, label='train')\n",
        "plt.plot(test_loss_history, label='test')\n",
        "plt.legend();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbiGWNiWDRG9"
      },
      "source": [
        "Самыми эффективными гиперпараметрами для улучшения качества модели оказались скорость обучения (ее уменьшение) и размерность слоев(увеличение).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TESo1PE9DRG_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}